{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cricket Player Rating System\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning & pre-processing, feature engineering and creation of an algorithm to rate cricket players and discover their overall ranking:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r'datasets\\formatted_bbb_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1283363\n",
      "Number of columns: 88\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows:', df.shape[0])\n",
    "print('Number of columns:', df.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can convert out date column to datetime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2006-01-09T00:00Z\n",
       "1    2006-01-09T00:00Z\n",
       "2    2006-01-09T00:00Z\n",
       "Name: date, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0   2006-01-09\n",
       "1   2006-01-09\n",
       "2   2006-01-09\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['date'].head(3))\n",
    "\n",
    "# Convert our date column to datetime \n",
    "df['date'] = df['date'].str[:10]\n",
    "df['date'] = pd.to_datetime(df['date'], format='mixed')\n",
    "\n",
    "display(df['date'].head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function to create a subset of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_by_date(df, lower_date=None, upper_date=None):\n",
    "    \n",
    "    if df['date'].dtype == 'object':\n",
    "        # Convert dates to datetime\n",
    "        df['date'] = df['date'].str[:10]\n",
    "        df['date'] = pd.to_datetime(df['date'], format='mixed')\n",
    "\n",
    "    # Convert lower_date and upper_date to pandas datetime if they are strings\n",
    "    if isinstance(lower_date, str):\n",
    "        lower_date = pd.to_datetime(lower_date)\n",
    "    if isinstance(upper_date, str):\n",
    "        upper_date = pd.to_datetime(upper_date)\n",
    "\n",
    "    # Determine the earliest and latest dates in the dataframe\n",
    "    min_date = df['date'].min()\n",
    "    max_date = df['date'].max()\n",
    "\n",
    "    # Assign the earliest or latest date if lower_date or upper_date is not provided\n",
    "    lower_date = lower_date or min_date\n",
    "    upper_date = upper_date or max_date\n",
    "\n",
    "    # Filter the dataframe based on the date range\n",
    "    filtered_dataframe = df[(df['date'] >= lower_date) & (df['date'] <= upper_date)]\n",
    "\n",
    "    return filtered_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 301622\n",
      "Number of columns: 88\n"
     ]
    }
   ],
   "source": [
    "df = filter_dataframe_by_date(df, lower_date='2010-01-01', upper_date='2015-01-01')\n",
    "\n",
    "print('Number of rows:', df.shape[0])\n",
    "print('Number of columns:', df.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the max value for the overs column to see if we are only dealing with T20 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of overs: 50.0\n"
     ]
    }
   ],
   "source": [
    "# Show the max value in the overs column\n",
    "print('Max number of overs:', df['overs'].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we clearly have data for other tournaments with higher over limits in this dataset, we can remove these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40597 rows removed\n"
     ]
    }
   ],
   "source": [
    "rows_before = df.shape[0]\n",
    "\n",
    "# Identify event IDs with overs greater than 20\n",
    "event_ids_to_remove = df.loc[df['overs'] > 20, 'event_id'].unique()\n",
    "\n",
    "# Remove rows with event IDs that have overs greater than 20\n",
    "df = df.loc[~df['event_id'].isin(event_ids_to_remove)]\n",
    "\n",
    "rows_after = df.shape[0]\n",
    "print(rows_before-rows_after, 'rows removed')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we remove entries that have an over_limit value of over 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows removed\n"
     ]
    }
   ],
   "source": [
    "rows_before = df.shape[0]\n",
    "\n",
    "# Identify event IDs with overs greater than 20\n",
    "event_ids_to_remove = df.loc[df['over_limit'] > 20, 'event_id'].unique()\n",
    "\n",
    "# Remove rows with event IDs that have overs greater than 20\n",
    "df = df.loc[~df['event_id'].isin(event_ids_to_remove)]\n",
    "\n",
    "rows_after = df.shape[0]\n",
    "print(rows_before-rows_after, 'rows removed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will need player names for our final ratings, we can build functions that check that each id for a player has a unique name, and if not to replace the name with the most common name for that ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check number of names for each id\n",
    "def check_duplicate_names_for_id(df, id, name):\n",
    "    num_duplicate_names = (df.groupby(id)[name].nunique() > 1).sum()\n",
    "    return num_duplicate_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace duplicate names in the DataFrame for a given id and name column\n",
    "def replace_duplicate_names(df, id, name):\n",
    "    \n",
    "    num_duplicates = check_duplicate_names_for_id(df, id, name)\n",
    "    \n",
    "    if num_duplicates == 0:\n",
    "        print('No duplicate name(s) for:', id)\n",
    "    else:        \n",
    "        print(f'{num_duplicates} duplicate names in {id}')\n",
    "        \n",
    "        # Get the ids with the most duplicate names, sorted in descending order\n",
    "        duplicate_list = df.groupby(id)[name].nunique().sort_values(ascending=False).head(num_duplicates)\n",
    "        \n",
    "        # Iterate through the duplicate ids\n",
    "        for duplicate_id in duplicate_list.index:\n",
    "            # Get the unique names for the current duplicate id, sorted by frequency\n",
    "            unique_names = df[df[id] == duplicate_id][name].value_counts().sort_values(ascending=False).index\n",
    "            \n",
    "            # Select the most common name as the top name\n",
    "            top_name = unique_names[0]\n",
    "            \n",
    "            # Iterate through the remaining unique names\n",
    "            for player_name in unique_names[1:]:\n",
    "                # Replace each unique name with the top name in the dataframe\n",
    "                df[name] = df[name].replace({player_name: top_name})\n",
    "                \n",
    "                print(f'{player_name} replaced with {top_name}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define all the id and name pairs and run the above functions to ensure each player ID has a unique name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of player id and name pairs\n",
    "role_id_names = {'bowler_id': 'bowler_name',\n",
    "            'batter_id': 'batsman_striker_name'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate name(s) for: bowler_id\n",
      "\n",
      "\n",
      "No duplicate name(s) for: batter_id\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dictionary and replace duplicates\n",
    "for id, name in role_id_names.items():\n",
    "    replace_duplicate_names(df, id, name)\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for the team IDs and team names to ensure there are no duplicates here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of team id and name pairs\n",
    "team_id_names = {'bowler_team_id': 'bowler_team_name',\n",
    "            'batsman_striker_team_id': 'batsman_striker_team_name'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate name(s) for: bowler_team_id\n",
      "\n",
      "\n",
      "No duplicate name(s) for: batsman_striker_team_id\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dictionary and replace duplicates\n",
    "for id, name in team_id_names.items():\n",
    "    replace_duplicate_names(df, id, name)\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that every team ID has a unique team name. \n",
    "\n",
    "Now we will look into missing values for the bowler_id and batter_id columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 missing bowler_id values\n"
     ]
    }
   ],
   "source": [
    "# Print the count of missing 'bowler_id' values\n",
    "print(df['bowler_id'].isna().sum(), 'missing bowler_id values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a notable number of missing values for bowler_id. We can have a look at some of these rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>innings</th>\n",
       "      <th>overs</th>\n",
       "      <th>ball_no</th>\n",
       "      <th>match_ball_no</th>\n",
       "      <th>innings_runs</th>\n",
       "      <th>innings_wickets</th>\n",
       "      <th>innings_target</th>\n",
       "      <th>innings_remaining_runs</th>\n",
       "      <th>...</th>\n",
       "      <th>over_wickets</th>\n",
       "      <th>over_actual</th>\n",
       "      <th>over_unique</th>\n",
       "      <th>dismissal_dismissal</th>\n",
       "      <th>dismissal_bowled</th>\n",
       "      <th>dismissal_minutes</th>\n",
       "      <th>dismissal_bowler_id</th>\n",
       "      <th>dismissal_bowler_name</th>\n",
       "      <th>dismissal_batsman_id</th>\n",
       "      <th>dismissal_batsman_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83148</th>\n",
       "      <td>110010</td>\n",
       "      <td>440100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25483.0</td>\n",
       "      <td>Simon Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83149</th>\n",
       "      <td>110020</td>\n",
       "      <td>440100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25475.0</td>\n",
       "      <td>Ross Lyons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83150</th>\n",
       "      <td>110030</td>\n",
       "      <td>440100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25475.0</td>\n",
       "      <td>Ross Lyons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83151</th>\n",
       "      <td>110040</td>\n",
       "      <td>440100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25475.0</td>\n",
       "      <td>Ross Lyons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83152</th>\n",
       "      <td>110050</td>\n",
       "      <td>440100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25475.0</td>\n",
       "      <td>Ross Lyons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  event_id  innings  overs  ball_no  match_ball_no  innings_runs   \n",
       "83148  110010    440100      1.0   10.1      1.0           61.0          66.0  \\\n",
       "83149  110020    440100      1.0   10.2      2.0           62.0          66.0   \n",
       "83150  110030    440100      1.0   10.3      3.0           63.0          66.0   \n",
       "83151  110040    440100      1.0   10.4      4.0           64.0          66.0   \n",
       "83152  110050    440100      1.0   10.5      5.0           65.0          66.0   \n",
       "\n",
       "       innings_wickets  innings_target  innings_remaining_runs  ...   \n",
       "83148              6.0             0.0                     NaN  ...  \\\n",
       "83149              6.0             0.0                     NaN  ...   \n",
       "83150              6.0             0.0                     NaN  ...   \n",
       "83151              6.0             0.0                     NaN  ...   \n",
       "83152              6.0             0.0                     NaN  ...   \n",
       "\n",
       "       over_wickets  over_actual  over_unique  dismissal_dismissal   \n",
       "83148           0.0         10.1        10.01                False  \\\n",
       "83149           0.0         10.2        10.02                False   \n",
       "83150           0.0         10.3        10.03                False   \n",
       "83151           0.0         10.4        10.04                False   \n",
       "83152           0.0         10.5        10.05                False   \n",
       "\n",
       "       dismissal_bowled  dismissal_minutes  dismissal_bowler_id   \n",
       "83148             False                0.0                  NaN  \\\n",
       "83149             False                0.0                  NaN   \n",
       "83150             False                0.0                  NaN   \n",
       "83151             False                0.0                  NaN   \n",
       "83152             False                0.0                  NaN   \n",
       "\n",
       "       dismissal_bowler_name  dismissal_batsman_id dismissal_batsman_name  \n",
       "83148                    NaN               25483.0            Simon Smith  \n",
       "83149                    NaN               25475.0             Ross Lyons  \n",
       "83150                    NaN               25475.0             Ross Lyons  \n",
       "83151                    NaN               25475.0             Ross Lyons  \n",
       "83152                    NaN               25475.0             Ross Lyons  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the first few rows where 'bowler_id' is NaN\n",
    "df[df['bowler_id'].isna()].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there is some messy data here so we can remove all rows with this ID value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 rows removed\n"
     ]
    }
   ],
   "source": [
    "# Get the old number of rows in the dataframe \n",
    "rows_before = df.shape[0]\n",
    "\n",
    "# Drop rows where 'id' matches 999999999999999\n",
    "df = df.drop(df[df['id'] == 999999999999999].index)\n",
    "\n",
    "# Get the new number of rows in the dataframe \n",
    "rows_after = df.shape[0]\n",
    "\n",
    "# Show how many rows were removed\n",
    "print(rows_before-rows_after, 'rows removed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can no look into filling null values for bowler_id. \n",
    "\n",
    "We know that the same bowler will be bowling every ball for a certain over in an innings in a match, therefore we can forward fill all missing values for this over from values we have in this over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 missing bowler_id values\n",
      "15 missing bowler_id values\n"
     ]
    }
   ],
   "source": [
    "# Print the old count of missing 'bowler_id' values\n",
    "print(df['bowler_id'].isna().sum(), 'missing bowler_id values')\n",
    "\n",
    "# Forward fill missing values based on 'event_id', 'innings', and the same value before the decimal point for 'overs'\n",
    "df['bowler_id'] = df.groupby(['event_id', 'innings', df['overs'].apply(int)])['bowler_id'].fillna(method='ffill')\n",
    "\n",
    "# Print the new count of missing 'bowler_id' values\n",
    "print(df['bowler_id'].isna().sum(), 'missing bowler_id values')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has allowed us to fill a significant number of missing values. We could fill the further missing values through external research, but giving that this is only a small percentage we will leave them.\n",
    "\n",
    "We can create a function to impute missing names from their ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill names from name ID\n",
    "def fill_name_from_id(df, id, name):\n",
    "\n",
    "    # Iterate over the DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isnull(row[name]):\n",
    "            # Retrieve the bowler_id for the current row\n",
    "            player_id = row[id]\n",
    "\n",
    "            # Find matching names for the bowler_id\n",
    "            matching_names = df.loc[df[id] == player_id, name]\n",
    "\n",
    "            # If matching names exist, assign the first matching name to the current row's 'bowler_name'\n",
    "            if not matching_names.empty:\n",
    "                df.at[index, name] = matching_names.values[0]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 missing bowler_name values\n",
      "15 missing bowler_name values\n"
     ]
    }
   ],
   "source": [
    "# Print the count of missing 'bowler_name' values\n",
    "print(df['bowler_name'].isna().sum(), 'missing bowler_name values')\n",
    "\n",
    "# Use the function to fill missing names from ID\n",
    "fill_name_from_id(df, 'bowler_id', 'bowler_name')\n",
    "\n",
    "# Print the count of missing 'bowler_name' values after filling missing values\n",
    "print(df['bowler_name'].isna().sum(), 'missing bowler_name values')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally fill all remaining missing bowler_id and bowler_name values with an Unknown value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing bowler_name values\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'bowler_id' column with 'Unknown'\n",
    "df['bowler_id'] = df['bowler_id'].fillna('Unknown')\n",
    "\n",
    "# Fill missing values in 'bowler_name' column with 'Unknown'\n",
    "df['bowler_name'] = df['bowler_name'].fillna('Unknown')\n",
    "\n",
    "# Print the count of missing 'bowler_name' values\n",
    "print(df['bowler_name'].isna().sum(), 'missing bowler_name values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look into filling missing batter_id values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 missing batter_id values\n"
     ]
    }
   ],
   "source": [
    "# Print the count of missing 'batter_id' values\n",
    "print(df['batter_id'].isna().sum(), 'missing batter_id values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we know that for any match and innings, the batter should remain the same provided there are no wickets lost and the runs scored is of an even value. Therefore we can use this information to fill in any missing values for batter_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 missing batter_id values\n"
     ]
    }
   ],
   "source": [
    "# Create a mask based on specific conditions\n",
    "mask = (\n",
    "    ((df['score_value'].shift(1) % 2 == 0) & (df['wickets_lost'].shift(1) == 0)) &  # If the previous score is even and no wickets were lost\n",
    "    (df['event_id'].shift(1) == df['event_id']) &  # If the previous event_id matches the current event_id\n",
    "    (df['innings'].shift(1) == df['innings'])  # If the previous innings value matches the current innings value\n",
    ")\n",
    "\n",
    "# Initialise variables for missing count\n",
    "prev_missing_count = float('inf')\n",
    "curr_missing_count = df['batter_id'].isna().sum()\n",
    "\n",
    "# Iteratively fill missing values until the count stabilizes\n",
    "while curr_missing_count != prev_missing_count:\n",
    "    prev_missing_count = curr_missing_count\n",
    "\n",
    "    # Fill missing values in the 'batter_id' column using the previous non-missing value\n",
    "    df.loc[mask, 'batter_id'] = df['batter_id'].fillna(df['batter_id'].shift(1))\n",
    "\n",
    "    # Update the current missing count\n",
    "    curr_missing_count = df['batter_id'].isna().sum()\n",
    "\n",
    "# Print the new count of missing 'batter_id' values\n",
    "print(curr_missing_count, 'missing batter_id values')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, while we could fill in the further missing values through further research, we will keep these blank to save time. \n",
    "\n",
    "Similarly to before, we can use the filled ID values to fill in the batter name values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 missing batsman_striker_name values\n",
      "8 missing batsman_striker_name values\n"
     ]
    }
   ],
   "source": [
    "# Print the count of missing 'batsman_striker_name' values\n",
    "print(df['batsman_striker_name'].isna().sum(), 'missing batsman_striker_name values')\n",
    "\n",
    "# Use the function to fill missing names from ID\n",
    "fill_name_from_id(df, 'batter_id', 'batsman_striker_name')\n",
    "\n",
    "# Print the count of missing 'batsman_striker_name' values after filling missing values\n",
    "print(df['batsman_striker_name'].isna().sum(), 'missing batsman_striker_name values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, again we can fill the missing values with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing batsman_striker_name values\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'batter_id' column with 'Unknown'\n",
    "df['batter_id'] = df['batter_id'].fillna('Unknown')\n",
    "\n",
    "# Fill missing values in 'batsman_striker_name' column with 'Unknown'\n",
    "df['batsman_striker_name'] = df['batsman_striker_name'].fillna('Unknown')\n",
    "\n",
    "# Print the count of missing 'batsman_striker_name' values\n",
    "print(df['batsman_striker_name'].isna().sum(), 'missing batsman_striker_name values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a feature that shows whether the current batter players for the home side. We can do this by checking whether the away score is 0 in each case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial value of the 'is_home_batter' column to 0 for all rows\n",
    "df['is_home_batter'] = 0\n",
    "\n",
    "# Update the 'is_home_batter' column to 1 for rows where the 'away_score' is '0'\n",
    "df.loc[df['away_score'] == '0', 'is_home_batter'] = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each event_id, each player should only have one value for is_home_batter, we can check that this is definitely the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_id  batter_id\n",
      "693019    21577.0      2\n",
      "          230855.0     2\n",
      "Name: is_home_batter, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group the dataframe by 'event_id' and 'batter_id', then count the number of unique values in 'is_home_batter' column\n",
    "grouped = df.groupby(['event_id', 'batter_id'])['is_home_batter'].nunique()\n",
    "\n",
    "# Filter the groups where the count of unique values is greater than 1\n",
    "result = grouped.loc[lambda x: x > 1]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we would expect to have discrepancies for 'Unknown', there are two players in one match that have two values for is_home_batter so we can look further into this match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>innings</th>\n",
       "      <th>batter_id</th>\n",
       "      <th>batsman_striker_name</th>\n",
       "      <th>batsman_striker_team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333209</th>\n",
       "      <td>693019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21577.0</td>\n",
       "      <td>Peter Trego</td>\n",
       "      <td>Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333210</th>\n",
       "      <td>693019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21577.0</td>\n",
       "      <td>Peter Trego</td>\n",
       "      <td>Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333239</th>\n",
       "      <td>693019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21577.0</td>\n",
       "      <td>Peter Trego</td>\n",
       "      <td>Gloucestershire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        event_id  innings batter_id batsman_striker_name   \n",
       "333209    693019      1.0   21577.0          Peter Trego  \\\n",
       "333210    693019      1.0   21577.0          Peter Trego   \n",
       "333239    693019      2.0   21577.0          Peter Trego   \n",
       "\n",
       "       batsman_striker_team_name  \n",
       "333209                  Somerset  \n",
       "333210                  Somerset  \n",
       "333239           Gloucestershire  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame based on specific conditions\n",
    "filtered_df = df[(df['event_id'] == 693019) & (df['batter_id'] == 21577.0)]\n",
    "\n",
    "# Select specific columns from the filtered DataFrame\n",
    "selected_columns = filtered_df[['event_id', 'innings', 'batter_id', 'batsman_striker_name', 'batsman_striker_team_name']]\n",
    "\n",
    "# Retrieve the last 3 rows of the selected columns\n",
    "selected_columns.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>innings</th>\n",
       "      <th>batter_id</th>\n",
       "      <th>batsman_striker_name</th>\n",
       "      <th>batsman_striker_team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333225</th>\n",
       "      <td>693019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230855.0</td>\n",
       "      <td>Craig Kieswetter</td>\n",
       "      <td>Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333231</th>\n",
       "      <td>693019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230855.0</td>\n",
       "      <td>Craig Kieswetter</td>\n",
       "      <td>Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333276</th>\n",
       "      <td>693019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>230855.0</td>\n",
       "      <td>Craig Kieswetter</td>\n",
       "      <td>Gloucestershire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        event_id  innings batter_id batsman_striker_name   \n",
       "333225    693019      1.0  230855.0     Craig Kieswetter  \\\n",
       "333231    693019      1.0  230855.0     Craig Kieswetter   \n",
       "333276    693019      2.0  230855.0     Craig Kieswetter   \n",
       "\n",
       "       batsman_striker_team_name  \n",
       "333225                  Somerset  \n",
       "333231                  Somerset  \n",
       "333276           Gloucestershire  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame based on specific conditions\n",
    "filtered_df = df[(df['event_id'] == 693019) & (df['batter_id'] == 230855.0)]\n",
    "\n",
    "# Select specific columns from the filtered DataFrame\n",
    "selected_columns = filtered_df[['event_id', 'innings', 'batter_id', 'batsman_striker_name', 'batsman_striker_team_name']]\n",
    "\n",
    "# Retrieve the last 3 rows of the selected columns\n",
    "selected_columns.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there was clearly an issue collecting data for this particular match. Therefore, we can we define a function that replaces discrepancies such as these wiht 'Unknown':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace discrepancies in specified columns with 'Unknown' values in the DataFrame.\n",
    "def replace_discrepancies_with_unknown(df, discrepancy_column, column_to_replace1, column_to_replace2):\n",
    "\n",
    "    # Group the DataFrame by 'event_id' and the first replacement column, and count the number of unique values in the discrepancy column\n",
    "    discrepancy_df = df.groupby(['event_id', column_to_replace1])[discrepancy_column].nunique().loc[lambda x: x > 1].reset_index()[['event_id', column_to_replace1]]\n",
    "\n",
    "    for i, row in discrepancy_df.iterrows():\n",
    "        \n",
    "        # Define event_id and batter_id\n",
    "        event_id = row['event_id']\n",
    "        id = row[column_to_replace1]\n",
    "\n",
    "        if id == 'Unknown':\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Filter the DataFrame based on the specified conditions\n",
    "            filtered_df = df.loc[(df['event_id'] == event_id) & (df[column_to_replace1] == id)]\n",
    "\n",
    "            # Calculate the most common value\n",
    "            most_common_value = filtered_df[discrepancy_column].mode().values[0]\n",
    "\n",
    "            # Replace any value except the most common value with 'Unknown Batter'\n",
    "            filtered_df.loc[filtered_df[discrepancy_column] != most_common_value, column_to_replace1] = 'Unknown'\n",
    "            filtered_df.loc[filtered_df[discrepancy_column] != most_common_value, column_to_replace2] = 'Unknown'\n",
    "\n",
    "            # Update the original DataFrame with the modified values\n",
    "            df.update(filtered_df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the above function on discrepancies with is_home_batter\n",
    "df = replace_discrepancies_with_unknown(df, 'is_home_batter', 'batter_id', 'batsman_striker_name')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check that Unknown is the only value remaining with multiple unique values for is_home_batter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: is_home_batter, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Group the dataframe by 'event_id' and 'batter_id', then count the number of unique values in 'is_home_batter' column\n",
    "grouped = df.groupby(['event_id', 'batter_id'])['is_home_batter'].nunique()\n",
    "\n",
    "# Filter the groups where the count of unique values is greater than 1\n",
    "result = grouped.loc[lambda x: x > 1]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do a similar process for is_home_bowler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign 0 to the 'is_home_bowler' column for all rows in the DataFrame\n",
    "df['is_home_bowler'] = 0\n",
    "\n",
    "# Set the value of 'is_home_bowler' to 1 for rows where the 'home_score' column is '0'\n",
    "df.loc[df['home_score'] == '0', 'is_home_bowler'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_id  bowler_id\n",
      "693019    211748.0     2\n",
      "          451782.0     2\n",
      "Name: is_home_bowler, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group the dataframe by 'event_id' and 'bowler_id', then count the number of unique values in 'is_home_bowler' column\n",
    "grouped = df.groupby(['event_id', 'bowler_id'])['is_home_bowler'].nunique()\n",
    "\n",
    "# Filter the groups where the count of unique values is greater than 1\n",
    "result = grouped.loc[lambda x: x > 1]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is again an issue with the collected data for the same match as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>innings</th>\n",
       "      <th>bowler_id</th>\n",
       "      <th>bowler_name</th>\n",
       "      <th>bowler_team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333227</th>\n",
       "      <td>693019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211748.0</td>\n",
       "      <td>Benny Howell</td>\n",
       "      <td>Gloucestershire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333228</th>\n",
       "      <td>693019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211748.0</td>\n",
       "      <td>Benny Howell</td>\n",
       "      <td>Gloucestershire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333276</th>\n",
       "      <td>693019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>211748.0</td>\n",
       "      <td>Benny Howell</td>\n",
       "      <td>Somerset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        event_id  innings bowler_id   bowler_name bowler_team_name\n",
       "333227    693019      1.0  211748.0  Benny Howell  Gloucestershire\n",
       "333228    693019      1.0  211748.0  Benny Howell  Gloucestershire\n",
       "333276    693019      2.0  211748.0  Benny Howell         Somerset"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame based on specific conditions\n",
    "filtered_df = df[(df['event_id'] == 693019) & (df['bowler_id'] == 211748.0)]\n",
    "\n",
    "# Select specific columns from the filtered DataFrame\n",
    "selected_columns = filtered_df[['event_id', 'innings', 'bowler_id', 'bowler_name', 'bowler_team_name']]\n",
    "\n",
    "# Retrieve the last three rows from the selected columns\n",
    "selected_columns.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can use our defined function from before to replace the incorrect value with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the above function on discrepancies with is_home_bowler\n",
    "df = replace_discrepancies_with_unknown(df, 'is_home_bowler', 'bowler_id', 'bowler_name')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again check that the discrepacnies have been removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: is_home_bowler, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Group the dataframe by 'event_id' and 'bowler_id', then count the number of unique values in 'is_home_bowler' column\n",
    "grouped = df.groupby(['event_id', 'bowler_id'])['is_home_bowler'].nunique()\n",
    "\n",
    "# Filter the groups where the count of unique values is greater than 1\n",
    "result = grouped.loc[lambda x: x > 1]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look into events that only have one value for innings and remove these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809 rows removed\n"
     ]
    }
   ],
   "source": [
    "rows_before = df.shape[0]\n",
    "\n",
    "# Filter event_ids with only one unique innings value\n",
    "unique_innings = df.groupby('event_id')['innings'].nunique()\n",
    "filtered_event_ids = unique_innings[unique_innings == 1].index\n",
    "\n",
    "# Create a new dataframe without the filtered event_ids\n",
    "df = df[~df['event_id'].isin(filtered_event_ids)]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "rows_after = df.shape[0]\n",
    "print(rows_before-rows_after, 'rows removed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before we start seperately looking into build seperate dataframes for rating batters and bowlers, we can add preliminary columns for batter_rating and bowler_rating which we will come back to later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add preliminary columns for batter_rating and bowler_rating\n",
    "df['batter_rating'] = 1\n",
    "df['bowler_rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pre_processing(df):\n",
    "\n",
    "    if df['date'].dtype == 'object':\n",
    "        # Convert dates to datetime\n",
    "        df['date'] = df['date'].str[:10]\n",
    "        df['date'] = pd.to_datetime(df['date'], format='mixed')\n",
    "\n",
    "    # Identify event IDs with overs greater than 20\n",
    "    event_ids_to_remove = df.loc[df['overs'] > 20, 'event_id'].unique()\n",
    "\n",
    "    # Remove rows with event IDs that have overs greater than 20\n",
    "    df = df.loc[~df['event_id'].isin(event_ids_to_remove)]\n",
    "\n",
    "    # Identify event IDs with overs greater than 20\n",
    "    event_ids_to_remove = df.loc[df['over_limit'] > 20, 'event_id'].unique()\n",
    "\n",
    "    # Remove rows with event IDs that have overs greater than 20\n",
    "    df = df.loc[~df['event_id'].isin(event_ids_to_remove)]\n",
    "\n",
    "    # Create a dictionary of player id and name pairs\n",
    "    role_id_names = {'bowler_id': 'bowler_name',\n",
    "                'batter_id': 'batsman_striker_name',\n",
    "                'nonstriker_id': 'batsman_nonstriker_name',\n",
    "                'dismissal_bowler_id': 'dismissal_bowler_name',\n",
    "                'dismissal_batsman_id': 'dismissal_batsman_name'}\n",
    "\n",
    "    # Iterate through the dictionary and replace duplicates\n",
    "    for id, name in role_id_names.items():\n",
    "        replace_duplicate_names(df, id, name)\n",
    "        print('\\n')\n",
    "\n",
    "    # Create a dictionary of team id and name pairs\n",
    "    team_id_names = {'bowler_team_id': 'bowler_team_name',\n",
    "                'batsman_striker_team_id': 'batsman_striker_team_name',\n",
    "                'batsman_nonstriker_team_id': 'batsman_nonstriker_team_name'}\n",
    "\n",
    "    # Iterate through the dictionary and replace duplicates\n",
    "    for id, name in team_id_names.items():\n",
    "        replace_duplicate_names(df, id, name)\n",
    "        print('\\n')\n",
    "\n",
    "    # Drop rows where 'id' matches 999999999999999\n",
    "    df = df.drop(df[df['id'] == 999999999999999].index)\n",
    "\n",
    "    # Forward fill missing values based on 'event_id', 'innings', and the same value before the decimal point for 'overs'\n",
    "    df['bowler_id'] = df.groupby(['event_id', 'innings', df['overs'].apply(int)])['bowler_id'].fillna(method='ffill')\n",
    "\n",
    "    # Use the function to fill missing names from ID\n",
    "    fill_name_from_id(df, 'bowler_id', 'bowler_name')\n",
    "\n",
    "    # Fill missing values in 'bowler_id' and 'bowler_name' columns with 'Unknown'\n",
    "    df['bowler_id'] = df['bowler_id'].fillna('Unknown')\n",
    "    df['bowler_name'] = df['bowler_name'].fillna('Unknown')\n",
    "\n",
    "    # Create a mask based on specific conditions\n",
    "    mask = (\n",
    "        ((df['score_value'].shift(1) % 2 == 0) & (df['wickets_lost'].shift(1) == 0)) &  # If the previous score is even and no wickets were lost\n",
    "        (df['event_id'].shift(1) == df['event_id']) &  # If the previous event_id matches the current event_id\n",
    "        (df['innings'].shift(1) == df['innings'])  # If the previous innings value matches the current innings value\n",
    "    )\n",
    "\n",
    "    # Initialise variables for missing count\n",
    "    prev_missing_count = float('inf')\n",
    "    curr_missing_count = df['batter_id'].isna().sum()\n",
    "\n",
    "    # Iteratively fill missing values until the count stabilizes\n",
    "    while curr_missing_count != prev_missing_count:\n",
    "        prev_missing_count = curr_missing_count\n",
    "\n",
    "        # Fill missing values in the 'batter_id' column using the previous non-missing value\n",
    "        df.loc[mask, 'batter_id'] = df['batter_id'].fillna(df['batter_id'].shift(1))\n",
    "\n",
    "        # Update the current missing count\n",
    "        curr_missing_count = df['batter_id'].isna().sum()\n",
    "\n",
    "    # Use the function to fill missing names from ID\n",
    "    fill_name_from_id(df, 'batter_id', 'batsman_striker_name')\n",
    "\n",
    "    # Fill missing values in 'batter_id' and 'batsman_striker_name' columnn with 'Unknown'\n",
    "    df['batter_id'] = df['batter_id'].fillna('Unknown')\n",
    "    df['batsman_striker_name'] = df['batsman_striker_name'].fillna('Unknown')\n",
    "\n",
    "    # Set the initial value of the 'is_home_batter' column to 0 for all rows\n",
    "    df['is_home_batter'] = 0\n",
    "\n",
    "    # Update the 'is_home_batter' column to 1 for rows where the 'away_score' is '0'\n",
    "    df.loc[df['away_score'] == '0', 'is_home_batter'] = 1\n",
    "\n",
    "    df = replace_discrepancies_with_unknown(df, 'is_home_batter', 'batter_id', 'batsman_striker_name')\n",
    "\n",
    "    # Assign 0 to the 'is_home_bowler' column for all rows in the DataFrame\n",
    "    df['is_home_bowler'] = 0\n",
    "\n",
    "    # Set the value of 'is_home_bowler' to 1 for rows where the 'home_score' column is '0'\n",
    "    df.loc[df['home_score'] == '0', 'is_home_bowler'] = 1\n",
    "\n",
    "    # Run the above function on discrepancies with is_home_bowler\n",
    "    df = replace_discrepancies_with_unknown(df, 'is_home_bowler', 'bowler_id', 'bowler_name')\n",
    "\n",
    "    # Step 2: Filter event_ids with only one unique innings value\n",
    "    unique_innings = df.groupby('event_id')['innings'].nunique()\n",
    "    filtered_event_ids = unique_innings[unique_innings == 1].index\n",
    "\n",
    "    # Step 3: Create a new DataFrame without the filtered event_ids\n",
    "    df = df[~df['event_id'].isin(filtered_event_ids)]\n",
    "\n",
    "    # We can set preliminary batter and bowling ratings for future use \n",
    "    df['bowler_rating'] = 1\n",
    "    df['batter_rating'] = 1\n",
    "\n",
    "    # Finally we can reset the index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = combine_pre_processing(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first create functions to extract a dataset each for batting and bowling analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bat_df(df):\n",
    "\n",
    "    # Create a new dataframe bat_df\n",
    "    bat_df = df[['event_id', 'innings', 'date', 'batter_id', 'batsman_striker_name', 'is_home_batter', 'batsman_striker_team_name', 'bowler_id', 'bowler_name', 'bowler_team_name', 'batter_balls_faced', 'batter_runs', 'home_score', 'away_score', 'dismissal_dismissal', 'batter_rating', 'bowler_rating']]\n",
    "\n",
    "    return bat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bowl_df(df):\n",
    "\n",
    "    # Create a new dataframe bowl_df\n",
    "    bowl_df = df[['event_id', 'innings', 'date', 'bowler_id', 'bowler_name', 'bowler_team_name', 'batter_id', 'batsman_striker_name', 'batsman_striker_team_name', 'is_home_bowler', 'batter_balls_faced', 'batter_runs', 'home_score', 'away_score', 'dismissal_dismissal', 'batter_rating', 'bowler_rating', 'bowler_balls', 'bowler_conceded', 'bowler_wickets', 'innings_no_balls', 'innings_wides']]\n",
    "\n",
    "    return bowl_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a function to create aggregated features for either the batting or bowling dataframe. (At the moment the batter_rating and bowler_ratings are all ones so finding the mean is redundant, but these will be updated later and this function will be run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agg_data(df, batter_or_bowler):\n",
    "\n",
    "    if batter_or_bowler == 'batter':\n",
    "\n",
    "        # Group the DataFrame 'bat_df' by 'batsman_striker_name' and 'event_id'\n",
    "        grouped_data = df.groupby(['batsman_striker_name', 'event_id'])\n",
    "\n",
    "        # Aggregate the grouped data using different aggregation functions for specific columns\n",
    "        aggregated_batsman_data = grouped_data.agg({\n",
    "            'batter_runs': 'last',\n",
    "            'batter_balls_faced': 'last',\n",
    "            'is_home_batter': 'mean',\n",
    "            'dismissal_dismissal': 'last',\n",
    "            'bowler_rating': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        return aggregated_batsman_data\n",
    "\n",
    "    elif batter_or_bowler == 'bowler':\n",
    "\n",
    "        # Group the DataFrame 'bowl_df' by 'bowler_name' and 'event_id'\n",
    "        grouped_data = df.groupby(['bowler_name', 'event_id'])\n",
    "\n",
    "        # Define a custom lambda function to count non-zero entries\n",
    "        count_non_zero = lambda x: (x != 0).sum()\n",
    "\n",
    "        # Aggregate the grouped data using different aggregation functions for specific columns\n",
    "        aggregated_bowler_data = grouped_data.agg({\n",
    "            'bowler_balls': 'max',\n",
    "            'bowler_conceded': 'max',\n",
    "            'bowler_wickets': 'max',\n",
    "            'innings_wides': count_non_zero,\n",
    "            'innings_no_balls': count_non_zero,\n",
    "            'is_home_bowler': 'mean',\n",
    "            'batter_rating': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        return aggregated_bowler_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a function to create a dataframe containing aggregated data on each match including runs and wickets for each team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_team_score_data(df):\n",
    "\n",
    "    # Group the DataFrame 'df' by 'event_id' and 'innings'\n",
    "    grouped_data = df.groupby(['event_id', 'bowler_team_id'])\n",
    "\n",
    "    # Aggregate the grouped data using different aggregation functions for specific columns\n",
    "    aggregated_innings_score_data = grouped_data.agg({\n",
    "        'date': 'last',\n",
    "        'home_score': 'last',\n",
    "        'away_score': 'last',\n",
    "        'match_ball_no': 'last'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Group the 'aggregated_team_score_data' DataFrame by 'event_id'\n",
    "    aggregated_team_score_data = aggregated_innings_score_data.groupby('event_id').agg({\n",
    "        'date': 'last',\n",
    "        'home_score': 'max',\n",
    "        'away_score': 'max',\n",
    "        'match_ball_no': ['last', 'first']\n",
    "    }).reset_index()\n",
    "\n",
    "    aggregated_team_score_data = pd.DataFrame(aggregated_team_score_data.values, columns=['event_id', 'date', 'home_score', 'away_score', 'home_balls', 'away_balls'])\n",
    "\n",
    "    # Create new columns 'home_runs' and 'home_wickets' \n",
    "    aggregated_team_score_data['home_runs'] = aggregated_team_score_data['home_score'].str.split('/').str[0]\n",
    "    aggregated_team_score_data['home_wickets'] = aggregated_team_score_data['away_score'].str.split('/').str[1]\n",
    "\n",
    "    # Create new columns 'away_runs' and 'away_wickets' \n",
    "    aggregated_team_score_data['away_runs'] = aggregated_team_score_data['away_score'].str.split('/').str[0]\n",
    "    aggregated_team_score_data['away_wickets'] = aggregated_team_score_data['home_score'].str.split('/').str[1]\n",
    "\n",
    "    return aggregated_team_score_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next create a function to merge these two aggregated functions together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_team_data(aggregated_team_score_data, aggregated_player_data):    \n",
    "    \n",
    "    # Merge 'aggregated_team_score_data' and 'aggregated_batsman_data' dataframes on 'event_id'\n",
    "    df = pd.merge(aggregated_team_score_data, aggregated_player_data, on='event_id')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function to add a column stating whether the bowler or batter won their match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_won_columns(df, batter_or_bowler):\n",
    "\n",
    "    # Create a new column named 'home_win'\n",
    "    df['home_win'] = 0\n",
    "\n",
    "    # Create a mask based on the condition of home_runs being greater than away_runs\n",
    "    mask = (df['home_runs'] > df['away_runs'])\n",
    "\n",
    "    # Assign the match result to the 'home_win' column using the mask\n",
    "    df.loc[mask, 'home_win'] = 1\n",
    "\n",
    "    if batter_or_bowler == 'batter':\n",
    "        # Create a new column named 'batter_won' based on certain conditions\n",
    "        df['batter_won'] = ((df['is_home_batter'] == 1) & (df['home_win'] == 1)) | ((df['is_home_batter'] == 0) & (df['home_win'] == 0))\n",
    "\n",
    "    elif batter_or_bowler == 'bowler':\n",
    "        # Create a new column named 'bowler_won' based on certain conditions\n",
    "        df['bowler_won'] = ((df['is_home_bowler'] == 1) & (df['home_win'] == 1)) | ((df['is_home_bowler'] == 0) & (df['home_win'] == 0))\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add a column showing the games played for each player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_games_played_column(df, batter_or_bowler):\n",
    "\n",
    "    if batter_or_bowler == 'batter':\n",
    "        df['games_played'] = df.groupby('batsman_striker_name').cumcount() + 1\n",
    "\n",
    "    elif batter_or_bowler == 'bowler':\n",
    "        df['games_played'] = df.groupby('bowler_name').cumcount() + 1\n",
    "\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look into creating some additional features. \n",
    "\n",
    "One such feature we would be interetsed in would be the percentage of a certain metric (i.e. wickets/runs) a player scored of the total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percentage_of_total_feature(df, player_data, home_data, away_data):\n",
    "\n",
    "    # Convert columns to float type\n",
    "    df[player_data] = df[player_data].astype(float)\n",
    "    df[home_data] = df[home_data].astype(float)\n",
    "    df[away_data] = df[away_data].astype(float) \n",
    "\n",
    "    # Define metrics\n",
    "    metric = player_data.split('_')[1]\n",
    "    percenatage_metric = '%_of_total_'+ metric\n",
    "\n",
    "    # Calculate percentage\n",
    "    df[percenatage_metric] = df[player_data]  / (df[home_data] + df[away_data])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important metric would be the number of runs a batter scored compared to how many balls he faced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_batter_run_rate(df):\n",
    "\n",
    "    # Create a new column named 'run_rate'\n",
    "    df['run_rate'] = np.where(\n",
    "        df['batter_balls_faced'] == 0,  # If 'batter_balls_faced' is 0, set the run rate to 0\n",
    "        0,\n",
    "        df['batter_runs'] / df['batter_balls_faced']  # Calculate the run rate\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for bowlers we would want a metric showing the opposition run rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_run_rate_against(df):\n",
    "\n",
    "    # Create a new column 'run_rate_against' \n",
    "    df['run_rate_against'] = np.where(\n",
    "        # If 'bowler_balls' is 0, set the value to NaN\n",
    "        df['bowler_balls'] == 0,\n",
    "        np.nan,\n",
    "        np.where(\n",
    "            # If 'bowler_conceded' is 0, set the value to 0.5 divided by 'bowler_balls'\n",
    "            df['bowler_conceded'] == 0,\n",
    "            0.5 / df['bowler_balls'],\n",
    "            # Otherwise, calculate the run rate by dividing 'bowler_conceded' by 'bowler_balls'\n",
    "            df['bowler_conceded'] / df['bowler_balls']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a function that adds all of these previously defined metrics onto our dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics_to_df(df, batter_or_bowler):\n",
    "\n",
    "    if batter_or_bowler == 'batter':\n",
    "        # Create %_of_total_runs column\n",
    "        df = create_percentage_of_total_feature(df, 'batter_runs', 'home_runs', 'away_runs')\n",
    "        \n",
    "        # Create run_rate column\n",
    "        df = calculate_batter_run_rate(df)\n",
    "\n",
    "        # Create batter_won column\n",
    "        df = create_player_won_columns(df, 'batter')\n",
    "\n",
    "        # Create games_played column\n",
    "        df = create_games_played_column(df, 'batter')\n",
    "    \n",
    "        # Extract necessary columns\n",
    "        bat_df = df[['event_id', 'date', 'batsman_striker_name', 'batter_runs', 'games_played', '%_of_total_runs', 'run_rate', 'dismissal_dismissal', 'batter_won', 'bowler_rating']]\n",
    "\n",
    "        return bat_df\n",
    "\n",
    "    elif batter_or_bowler == 'bowler':\n",
    "        # Create %_of_total_wickets\n",
    "        df = create_percentage_of_total_feature(df, 'bowler_wickets', 'home_wickets', 'away_wickets')\n",
    "\n",
    "        # Create %_of_total_balls\n",
    "        df = create_percentage_of_total_feature(df, 'bowler_balls', 'home_balls', 'away_balls')\n",
    "\n",
    "        # Create run_rate_against column\n",
    "        df = create_run_rate_against(df)\n",
    "\n",
    "        # Create batter_won column\n",
    "        df = create_player_won_columns(df, 'bowler')\n",
    "\n",
    "        # Create games_played column\n",
    "        df = create_games_played_column(df, 'bowler')\n",
    "\n",
    "        # Create new dataframe\n",
    "        bowl_df = df[['event_id', 'date', 'bowler_name', 'bowler_wickets', 'games_played', '%_of_total_wickets', '%_of_total_balls', 'run_rate_against', 'bowler_won', 'batter_rating', 'innings_no_balls', 'innings_wides']]\n",
    "\n",
    "        return bowl_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use these metrics to define scores for both batting and bowling while adding bonuses or penalties for certain instances such as the player's team winning the match, the batter not being dismissed or the bowler bowling wide or no-balls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rating_score(df, batter_or_bowler):\n",
    "\n",
    "    if batter_or_bowler == 'batter':\n",
    "\n",
    "        # Define our feature rating_score\n",
    "        df['rating_score'] = df['batter_runs'] * df['%_of_total_runs'] * df['run_rate']\n",
    "\n",
    "        # Add 30% to the rating_score when batter_won is True\n",
    "        df.loc[df['batter_won']==True, 'rating_score'] = df.loc[df['batter_won']==True, 'rating_score']* 1.3\n",
    "\n",
    "        # Add 10% to the rating_score when the batter wasn't dismissed\n",
    "        df.loc[df['dismissal_dismissal']==False, 'rating_score'] = df.loc[df['dismissal_dismissal']==False, 'rating_score'] * 1.1\n",
    "\n",
    "        # Calculate the mean of the rating_score column for each player \n",
    "        df['player_mean'] = df.groupby('batsman_striker_name')['rating_score'].transform(lambda x: x.expanding().mean())\n",
    "\n",
    "    if batter_or_bowler == 'bowler':\n",
    "\n",
    "        # Define our wicket rating score\n",
    "        df['wicket_rating_score'] = df['bowler_wickets'] * df['%_of_total_wickets'] \n",
    "\n",
    "        # Define our run rating score\n",
    "        df['run_rating_score'] = df['%_of_total_balls'] / df['run_rate_against'] \n",
    "        df['run_rating_score'] = df['run_rating_score'].fillna(0)\n",
    "\n",
    "        df['rating_score'] = (df['wicket_rating_score'] + df['run_rating_score']) / 2\n",
    "\n",
    "        # Add 30% to the rating_score when batter_won is True\n",
    "        df.loc[df['bowler_won']==True, 'rating_score'] = df.loc[df['bowler_won']==True, 'rating_score'] * 1.3\n",
    "\n",
    "        # Take 95% of score for every foul or wide ball\n",
    "        df['rating_score'] = df['rating_score'] * (0.95**(df['innings_no_balls']+df['innings_wides']))\n",
    "\n",
    "        # Calculate the mean of the rating_score column for each player \n",
    "        df['player_mean'] = df.groupby('bowler_name')['rating_score'].transform(lambda x: x.expanding().mean())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function that will normalise our scores around a mean of one and add upper and lower bounds if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_scores(df, score, lower_bound, upper_bound):\n",
    "\n",
    "    # Calculate the mean of the score column up to and including the current row\n",
    "    df['mean'] = df[score].expanding().mean()\n",
    "\n",
    "    # Calculate the scaling factor to normalize the distribution up to and including the current row\n",
    "    df['scale_factor'] = 1 / df['mean']\n",
    "\n",
    "    # Define column name\n",
    "    score_normalised = score + '_normalised'\n",
    "\n",
    "    # Apply the scaling factor to the rating_score column up to and including the current row\n",
    "    df[score_normalised] = df[score] * df['scale_factor']\n",
    "\n",
    "    # Apply upper and lower bound\n",
    "    df[score_normalised] = np.clip(df[score_normalised], lower_bound, upper_bound)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(['mean', 'scale_factor'], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a function that adds our scores and normalised scores to our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rating_features(df, batter_or_bowler):\n",
    "\n",
    "    if batter_or_bowler == 'batter':\n",
    "    \n",
    "        # Add batter_rating and player_mean\n",
    "        df = create_rating_score(df, 'batter')\n",
    "        \n",
    "        # Normalise rating_score\n",
    "        df = normalise_scores(df, 'rating_score', 0, 10)\n",
    "\n",
    "        # Normalise player_mean\n",
    "        df = normalise_scores(df, 'player_mean', 0.7, 1.3)\n",
    "        # Set as 1 for the first 10 games played\n",
    "        df.loc[df['games_played'] <= 10, 'player_mean_normalised'] = 1\n",
    "\n",
    "        # Normalise bowler_rating\n",
    "        df = normalise_scores(df, 'bowler_rating', 0.5, 1.5)\n",
    "\n",
    "    if batter_or_bowler == 'bowler':\n",
    "        \n",
    "        # Add bowler_rating and player_mean\n",
    "        df = create_rating_score(df, 'bowler')\n",
    "\n",
    "        # Normalise rating_score\n",
    "        df = normalise_scores(df, 'rating_score', 0, 10)\n",
    "\n",
    "        # Normalise player_mean\n",
    "        df = normalise_scores(df, 'player_mean', 0.7, 1.3)\n",
    "        # Set as 1 for the first 10 games played\n",
    "        df.loc[df['games_played'] <= 10, 'player_mean_normalised'] = 1\n",
    "\n",
    "        # Normalise batter_rating\n",
    "        df = normalise_scores(df, 'batter_rating', 0.5, 1.5)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function that combines all of the above steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df, batter_or_bowler):\n",
    "    \n",
    "    if batter_or_bowler == 'batter':\n",
    "    \n",
    "        bat_df = create_agg_data(df, 'batter')\n",
    "    \n",
    "        bat_df = merge_with_team_data(aggregated_team_score_data, bat_df)   \n",
    "\n",
    "        bat_df = add_metrics_to_df(bat_df, 'batter')\n",
    "        \n",
    "        bat_df = create_rating_score(bat_df, 'batter')\n",
    "\n",
    "        bat_df = add_rating_features(bat_df, 'batter')\n",
    "\n",
    "        return bat_df\n",
    "\n",
    "    elif batter_or_bowler == 'bowler':\n",
    "\n",
    "        bowl_df = create_agg_data(df, 'bowler')\n",
    "\n",
    "        bowl_df = merge_with_team_data(aggregated_team_score_data, bowl_df)   \n",
    "\n",
    "        bowl_df = add_metrics_to_df(bowl_df, 'bowler')\n",
    "\n",
    "        bowl_df = create_rating_score(bowl_df, 'bowler')\n",
    "\n",
    "        bowl_df = add_rating_features(bowl_df, 'bowler')\n",
    "\n",
    "        return bowl_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created both our batting and bowling dataframes, we can now create a function that adds batting and bowling rating scores back to our orginal cleaned dataframe. We can then re-run the previous function so that we now have a mean score rating for each opposing player per match: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rating_score(original_df, bat_df, bowl_df): \n",
    "\n",
    "    # Create a bowler_rating score\n",
    "    bowl_df['bowler_rating_score'] = bowl_df['rating_score_normalised'] * np.log1p(bowl_df['games_played'])\n",
    "\n",
    "    # Merge witrh original df\n",
    "    original_df = pd.merge(original_df, bowl_df[['event_id', 'bowler_name', 'bowler_rating_score']], on=['event_id', 'bowler_name'], how='left')\n",
    "    original_df['bowler_rating'] = original_df['bowler_rating_score']\n",
    "\n",
    "\n",
    "    # Create a batter_rating score\n",
    "    bat_df['batter_rating_score'] = bat_df['rating_score_normalised'] * np.log1p(bat_df['games_played'])\n",
    "\n",
    "    # Merge witrh original df\n",
    "    original_df = pd.merge(original_df, bat_df[['event_id', 'batsman_striker_name', 'batter_rating_score']], on=['event_id', 'batsman_striker_name'], how='left')\n",
    "    original_df['batter_rating'] = original_df['batter_rating_score']\n",
    "\n",
    "    # Get bat_df from the orginal df with the updated bowler_rating \n",
    "    bat_df2 = get_bat_df(original_df)\n",
    "\n",
    "    # Get bowl_df from the orginal df with the updated batter_rating\n",
    "    bowl_df2 = get_bowl_df(original_df)\n",
    "\n",
    "    # Run through the pre-processing steps again - batting\n",
    "    bat_df2 = pre_processing(bat_df2, 'batter')\n",
    "\n",
    "    # Run through the pre-processing steps again - bowling\n",
    "    bowl_df2 = pre_processing(bowl_df2, 'bowler')\n",
    "\n",
    "    # Drop new columns from original df\n",
    "    original_df.drop(['bowler_rating_score', 'batter_rating_score'], axis=1, inplace=True)\n",
    "\n",
    "    return bat_df2 , bowl_df2   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can combine the prepocessing steps with the above function that updates the player scores and re-runs the process to get our final dataframes for our algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bat_bowl_dfs(clean_df):\n",
    "    # Obtain the batting DataFrame\n",
    "    bat_df = get_bat_df(clean_df)\n",
    "    \n",
    "    # Obtain the bowling DataFrame\n",
    "    bowl_df = get_bowl_df(clean_df)\n",
    "    \n",
    "    # Get aggregated team score data (make it global so it can be used in exterior functions)\n",
    "    global aggregated_team_score_data\n",
    "    aggregated_team_score_data = get_agg_team_score_data(clean_df)\n",
    "    \n",
    "    # Perform pre-processing on the batting DataFrame\n",
    "    bat_df2 = pre_processing(bat_df, 'batter')\n",
    "    \n",
    "    # Perform pre-processing on the bowling DataFrame\n",
    "    bowl_df2 = pre_processing(bowl_df, 'bowler')\n",
    "    \n",
    "    # Update the rating score based on dataframes\n",
    "    bat_df3, bowl_df3 = update_rating_score(clean_df, bat_df2, bowl_df2)\n",
    "    \n",
    "    return bat_df3, bowl_df3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define our batting and bowling dataframes using the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_df, bowl_df = create_bat_bowl_dfs(clean_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First can define a function that will normalise our final rating scores on a scale out of 1000 (adding 10% to the max value to allow for improvement):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_rating_scale(df, rating):\n",
    "\n",
    "    min_value = df[rating].min()\n",
    "    max_value = df[rating].max() * 1.1\n",
    "\n",
    "    df[rating] = (df[rating] - min_value) * (1000 / (max_value - min_value))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can build our algorithm that takes the weighted average that sums the product normalised rating score, the normlaised opponents rating, the normalised players performance compared to their mean and the log of the number of games played, and divided it by the cumululative sum of the log of games played (with a power of 0.75 to add extra weight to players who have played more games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overall_rating_df(bat_df, bowl_df):\n",
    "\n",
    "    # Batters\n",
    "\n",
    "    # Create a new column for the overall_rating_batting\n",
    "    df['overall_rating_batting'] = 0.0\n",
    "\n",
    "    # Iterate over each unique batsman_striker_name\n",
    "    for batsman in bat_df['batsman_striker_name'].unique():\n",
    "        # Get the subset of rows for the current batsman\n",
    "        subset = bat_df[bat_df['batsman_striker_name'] == batsman]\n",
    "\n",
    "        # Initialise the cumulative sum variable\n",
    "        cumulative_sum = 0.0\n",
    "\n",
    "        # Iterate over each row in the subset\n",
    "        for i in range(len(subset)):\n",
    "            # Update the cumulative sum of the log of the games played\n",
    "            cumulative_sum += np.log1p(subset.iloc[i]['games_played'])\n",
    "\n",
    "            # Calculate the overall rating\n",
    "            overall_rating = (subset.iloc[:i+1]['rating_score_normalised'] * # Normalised rating score (capped at 10)\n",
    "                                subset.iloc[:i+1]['bowler_rating_normalised'] * # Normalised opponent rating (capped between 0.5 and 1.5)\n",
    "                                np.log1p(subset.iloc[:i+1]['games_played']) * # Log of games played\n",
    "                                subset.iloc[:i+1]['player_mean_normalised']).sum() / cumulative_sum ** 0.75 # We take the cumulative sum to the power of 0.75 to favour players who have played longer\n",
    "\n",
    "            # Assign the weighted average to the corresponding row\n",
    "            bat_df.at[subset.index[i], 'overall_rating_batting'] = overall_rating\n",
    "\n",
    "    # Normalise rating scale\n",
    "    bat_df = normalise_rating_scale(bat_df, 'overall_rating_batting')\n",
    "\n",
    "    # Bowlers\n",
    "\n",
    "    # Create a new column for the overall_rating_bowling\n",
    "    df['overall_rating_bowling'] = 0.0\n",
    "\n",
    "    # Iterate over each unique bowler_name\n",
    "    for bowler in bowl_df['bowler_name'].unique():\n",
    "        # Get the subset of rows for the current batsman\n",
    "        subset = bowl_df[bowl_df['bowler_name'] == bowler]\n",
    "\n",
    "        # Initialize the cumulative sum variable\n",
    "        cumulative_sum = 0.0\n",
    "\n",
    "        # Iterate over each row in the subset\n",
    "        for i in range(len(subset)):\n",
    "            # Update the cumulative sum of the log of the games played\n",
    "            cumulative_sum += np.log1p(subset.iloc[i]['games_played'])\n",
    "\n",
    "            # Calculate the overall rating\n",
    "            overall_rating = (subset.iloc[:i+1]['rating_score_normalised'] * # Normalised rating score (capped at 10)\n",
    "                                subset.iloc[:i+1]['batter_rating_normalised'] * # Normalised opponent rating (capped between 0.5 and 1.5)\n",
    "                                np.log1p(subset.iloc[:i+1]['games_played'])  * # Log of games played\n",
    "                                subset.iloc[:i+1]['player_mean_normalised'] ).sum() / cumulative_sum ** 0.75 # We take the cumulative sum to the power of 0.75 to favour players who have played longer\n",
    "\n",
    "            # Assign the weighted average to the corresponding row\n",
    "            bowl_df.at[subset.index[i], 'overall_rating_bowling'] = overall_rating\n",
    "\n",
    "    # Normalise rating scale\n",
    "    bowl_df = normalise_rating_scale(bowl_df, 'overall_rating_bowling')\n",
    "\n",
    "    return bat_df, bowl_df\n",
    "\n",
    "\n",
    "                \n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create the following function to run the above function and combine the two dataframes while also creating a rating value for all rounders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_ratings_df(bat_df, bowl_df):\n",
    "\n",
    "    bat_df2, bowl_df2 = create_overall_rating_df(bat_df, bowl_df)\n",
    "\n",
    "    # We rename our player names to be consistent\n",
    "    bat_df2 = bat_df2.rename({'batsman_striker_name': 'player_name'}, axis=1)\n",
    "    bowl_df2 = bowl_df2.rename({'bowler_name': 'player_name'}, axis=1)\n",
    "\n",
    "    # We merge our dataframes\n",
    "    merge_df = pd.merge(bat_df2, bowl_df2, on=['player_name', 'event_id', 'date'], suffixes=('_bat', '_bowl'), how='outer')\n",
    "\n",
    "    # Fill any nan values \n",
    "    merge_df = merge_df.fillna(0)\n",
    "\n",
    "    # Create an all-rounder column\n",
    "    merge_df['overall_rating_all_rounder'] = (merge_df['overall_rating_batting'] * merge_df['overall_rating_bowling']) / 1000\n",
    "\n",
    "    # Create games played for all-rounders\n",
    "    merge_df['games_played_all_round'] = merge_df.groupby('player_name').cumcount() + 1\n",
    "\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the function to get our rating dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = get_full_ratings_df(bat_df, bowl_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function to get mean monthly ratings and a player's ranking for each month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_rankings(df, rating_type):\n",
    "    rating_column = 'overall_rating_' + rating_type\n",
    "\n",
    "    # Get month and year\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "    # Create a dataframe with all possible combinations of 'player_name', 'month', and 'year'\n",
    "    all_combinations = pd.MultiIndex.from_product([df['player_name'].unique(), df['quarter'].unique(), df['year'].unique()], \n",
    "                                                  names=['player_name', 'quarter', 'year'])\n",
    "    all_combinations = all_combinations.to_frame(index=False)\n",
    "\n",
    "    # Merge the original data with all combinations to fill missing values\n",
    "    filled_data = pd.merge(all_combinations, df, how='left', on=['player_name', 'quarter', 'year'])\n",
    "\n",
    "    # Forward fill missing values\n",
    "    filled_data[rating_column].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Group the data by 'player_name', 'month', and 'year', and find the mean rating for each group\n",
    "    grouped_data = filled_data.groupby(['player_name', 'quarter', 'year']).agg({rating_column: 'mean'}).reset_index()\n",
    "\n",
    "    # Sort the data by 'year', 'month', and rating in descending, ascending, and descending order respectively\n",
    "    sorted_data = grouped_data.sort_values(['year', 'quarter', rating_column], ascending=[False, False, False])\n",
    "\n",
    "    # Reset the index of the sorted data and rename the columns\n",
    "    sorted_data.reset_index(drop=True, inplace=True)\n",
    "    sorted_data.columns = ['player_name', 'quarter', 'year', rating_column]\n",
    "\n",
    "    # Assign the ranking based on the sorted data for each month\n",
    "    sorted_data['ranking'] = sorted_data.groupby(['year', 'quarter'])[rating_column].rank(method='dense', ascending=False)\n",
    "\n",
    "    return sorted_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create the ranking dataframes and save them as files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_create_and_save_files(df):\n",
    "\n",
    "    # Create our ranking dataframes\n",
    "    df_batting = get_rankings(df, 'batting')\n",
    "    df_bowling = get_rankings(df, 'bowling')\n",
    "    df_all_rounder = get_rankings(df, 'all_rounder')\n",
    "\n",
    "    # Create  year and quarter columns on our dataframe\n",
    "    df['quarter'] = pd.to_datetime(df['date']).dt.quarter\n",
    "    df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "\n",
    "    # Find the max of each games played at each quarter\n",
    "    max_games_played_bat = df.groupby(['player_name', 'year', 'quarter'])['games_played_bat'].max().reset_index()\n",
    "    max_games_played_bowl = df.groupby(['player_name', 'year', 'quarter'])['games_played_bowl'].max().reset_index()\n",
    "    max_games_played_all_round = df.groupby(['player_name', 'year', 'quarter'])['games_played_all_round'].max().reset_index()\n",
    "\n",
    "    # Merge dataframes to get games played at each quarter\n",
    "    rank_df_batting = pd.merge(df_batting, max_games_played_bat[['player_name', 'year', 'quarter', 'games_played_bat']], on=['player_name', 'year', 'quarter'], how='left') \n",
    "    rank_df_bowling = pd.merge(df_bowling, max_games_played_bowl[['player_name', 'year', 'quarter', 'games_played_bowl']], on=['player_name', 'year', 'quarter'], how='left') \n",
    "    rank_df_all_rounder = pd.merge(df_all_rounder, max_games_played_all_round[['player_name', 'year', 'quarter', 'games_played_all_round']], on=['player_name', 'year', 'quarter'], how='left') \n",
    "\n",
    "    # Back fill any missing values and fill the rest with 0\n",
    "    rank_df_batting['games_played_bat'] = rank_df_batting.groupby('player_name')['games_played_bat'].fillna(method='bfill').fillna(1)\n",
    "    rank_df_bowling['games_played_bowl'] = rank_df_bowling.groupby('player_name')['games_played_bowl'].fillna(method='bfill').fillna(1)\n",
    "    rank_df_all_rounder['games_played_all_round'] = rank_df_all_rounder.groupby('player_name')['games_played_all_round'].fillna(method='bfill').fillna(1)\n",
    "\n",
    "    # Save to files\n",
    "    rank_df_batting.to_csv(r'datasets\\batting_rankings.csv', index=False)\n",
    "    rank_df_bowling.to_csv(r'datasets\\bowling_rankings.csv', index=False)\n",
    "    rank_df_all_rounder.to_csv(r'datasets\\all_rounder_rankings.csv', index=False)\n",
    "\n",
    "    return rank_df_batting, rank_df_bowling, rank_df_all_rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df_batting, rank_df_bowling, rank_df_all_rounder = merge_create_and_save_files(merge_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally create a function to extract a player's rating and ranking for a certain month and year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_rating_ranking(df, player_name, rating_type, year, quarter):\n",
    "\n",
    "    rank_df = get_rankings(df, rating_type)\n",
    "\n",
    "    row = rank_df[(rank_df['player_name'] == player_name) & (rank_df['year']==year) & (rank_df['quarter']==quarter)]\n",
    "\n",
    "    rating = row.at[row.index[0], 'overall_rating_'+rating_type].round(2)\n",
    "    ranking = int(row.at[row.index[0], 'ranking'])\n",
    "\n",
    "    result = {'Player Name': player_name, 'Rating': rating, 'Ranking': ranking}\n",
    "\n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
